<html><head>
<!-- Inserted by TRADOS: --><META HTTP-EQUIV="content-type" CONTENT="text/html; charset=UTF-8">
<title> - xrath.com 에서 번역됨</title>
</head>
<body bgcolor=#ffffff>
<hr>
<h1>제 2 장 :Sampled 패키지의 개요</h1>
<hr>
<form name="form1">
  <select name="menu1" onChange="Eminem_jumpMenu('parent',this,1)">
    <SCRIPT SRC="menu_script.js" language="JavaScript"></SCRIPT>
  </select>
</form>
<table width="80%" border="1" align="center" cellpadding="5" cellspacing="0" bordercolor="#000000" bgcolor="#FFFFCC">
  <tr>
    <td>
<h2><u>설명</u></h2>
      <ol>
<li>J2SE 5.0 으로 신규의 Direct Audio 믹서를 사용하면(자), Sun 의 레퍼런스 구현에서는, 사용 가능한 모든 사운드 카드, 지원 떠날 수 있어 모든 샘플링 레이트, 및 샘플 근처의 비트수를 사용할 수가 있습니다. </li>
<li>Direct Audio 믹서는 항상 Windows 의 디폴트입니다. Solaris 오디오 믹서가 유효한 경우는, Solaris 의 디폴트입니다 (Solaris 메뉴얼의 믹서에 관한 페이지를 참조). Linux 에서는, 믹싱을 지원하는 디바이스가 있는 경우에만 디폴트가 됩니다. </li>
<li>이유로서는, Direct Audio 믹서는 「직접」인 것으로부터,<code>SAMPLE_RATE</code> 컨트롤을 지원하지 않기 때문입니다.  </li>
<li>디폴트의 믹서는,<code>sound.properties</code> 파일을 사용해 선택할 수 있습니다. <br>
        </li>
      </ol></td>
  </tr>
</table>
<br>
<p><a name="112322"> </a> 여기에서는, Java<font size="-1"><sup>TM</sup></font> Sound API 의 디지털 오디오 아키텍쳐(architecture)의 개요를 설명합니다. 아키텍쳐(architecture)에는 <code>javax.sound.sampled</code> 패키지로부터 액세스 할 수 있습니다. 최초로, 패키지의 중심 기능인 서식 첨부의 오디오 데이터의 재생과 혼잡에 대해 설명합니다. 다음에, 재생과 혼잡에 필요한 3 개의 기본 요소인, 오디오 데이터 형식, 라인, 믹서에 대해 설명합니다. <code>Line</code> 인터페이스와 그 서브 인터페이스에 대해서는 간단하게 설명합니다. <strong></strong> 
</p><a name="112324"> </a> 
<h3> 설계 목표</h3>
<p><a name="112326"> </a> Java Sound API 의 요소의 고찰을 시작하기 전에,<code>javax.sound.sampled</code> 패키지의 자리 매김에 대해 설명합니다.
</p><a name="112328"> </a> 
<h4> 작업의 중심은 데이터 전송</h4>
<p><a name="112330"> <code>javax.sound.sampled</code> 패키지는, 음성의 이송에 관계하는 것입니다.  따로 표현하면(자), Java Sound API 는, 재생과 혼잡을 중심이다고 말할 수 있습니다. Java Sound API 가 임하는 주된 작업은, 서식 첨부 오디오 데이터의 바이트를 시스템의 내외에 어떻게 이동시키는가 하는 것입니다. 이 작업에는, 오디오 입출력 디바이스의 오픈, 및 리얼타임의 사운드 데이터를 포함하는 복수의 버퍼의 관리가 수반합니다. 또, 입력이든 출력이든, 복수의 오디오 스트림을 1 개의 스트림에 믹싱 하는 작업도 수반합니다. 사용자가 사운드의 플로우의 개시, 일시정지, 재개, 정지를 요구할 때, 시스템 내외에의 사운드의 전송은, 적절히 처리될 필요가 있습니다.  </p>
<p><a name="112332"> </a> 기본의 오디오 입출력을 중심적으로 지원하기 위해(때문에), Java Sound API 에는 다양한 오디오 데이터 형식간에서의 변환용의 메소드와 공통 타입의 사운드 파일의 읽어들여/기입용의 메소드가 제공되고 있습니다. 다만, 이 API 는 포괄적인 사운드 파일 툴 킷을 목표로 하는 것이 아닙니다. 특정의 Java Sound API 의 구현에서는, 파일 타입이나 데이터 형식 변환의 확장 세트의 지원를 필요로 하지 않습니다. 서드 파티의 서비스 프로바이더로부터, 기존의 구현에 플러그 인 해 추가의 파일 타입과 파일 변환을 지원할 수 있는 모듈이 제공되고 있습니다.  
</p><a name="112334"> </a> 
<h4> 오디오의 버퍼 첨부 처리와 버퍼 없음 처리</h4>
<p><a name="112336"> </a> Java Sound API 에서는, 버퍼 첨부 방식의 스트리밍과 버퍼 없음의 메모리 안쪽식의 스트리밍의 양쪽 모두로 음성의 전송을 처리할 수가 있습니다. 여기에서는 「스트리밍」이라고 하는 용어는 오디오 바이트의 리얼 타임 처리라고 하는 일반적인 의미로 사용해, 인터넷상에서 자주(잘) 사용되는 오디오 송신이라고 하는 특정의 형식에서 사용되는 경우를 가리키지 않습니다. 즉, 오디오의 스트림과는 단지, 처리 (재생, 녹음등)되는 레이트와 거의 같은 레이트로 도착하는 연속한 오디오 바이트군입니다. 바이트에 대한 조작은, 모든 데이터가 도착하기 전에 개시합니다. 스트리밍 모델로, 특히 오디오 출력은 아니고 오디오 입력의 경우는, 사운드의 길이와 모든 것이 도착할 때까지의 시간을 미리 알고 있다고는 할 수 없습니다. 조작이 정지할 때까지, 버퍼내의 오디오 데이터를 한 번에 1 개(살)씩 처리할 뿐입니다. 오디오 출력 (재생)의 경우도, 재생하는 사운드가 너무 커 한 번에 메모리에 들어가 싫은 실 나무는, 데이터를 버퍼링 할 필요가 있습니다. 즉, 오디오 바이트를 복수의 체크 (덩어리)로 나누어 사운드 엔진에 건네주어, 사운드 엔진은 적절한 때에 각 샘플의 재생 처리를 실시합니다. 각 체크의 적정한 데이터량을 간단하게 알기 위한 기구가 준비되어 있습니다.
</p>
<p><a name="112339"> </a> Java Sound API 에서는, 재생만의 경우는 버퍼 없음의 전송도 가능합니다만, 모든 오디오 데이터가 수중에 있어, 메모리에 다 들어가는 사이즈인 것이 조건입니다. 이 경우는, 응용 프로그램에 의한 오디오의 버퍼링은 필요 없습니다만, 필요에 따라서 버퍼 첨부의 리얼타임 기법을 이용할 수도 있습니다. 또, 미리 사운드 전체를 일단 메모리에 로드해 두고 나서 재생할 수도 있습니다. 이 방법에서는 미리 모든 사운드 데이터가 로드 되고 있으므로, 예를 들어 사용자가 「개시 (Start)」버튼을 클릭하는 것과 동시에 재생을 개시할 수 있습니다. 이 방법은, 최초의 버퍼가 가득 될 때까지 기다릴 필요가 있는 버퍼 첨부 모델보다 유리합니다. 게다가 버퍼 없음의 메모리 안쪽식의 모델에서는, 간단하게 사운드를 루프 (순환) 시키거나 데이터상의 임의의 위치에 세트 하거나 할 수가 있습니다.  </p>
<p><a name="112341"> </a> 이 재생을 위한 2 개의 모델에 대해서는 제 4 장<a href="chapter4.html">「오디오의 재생」</a>으로 상세하게 설명합니다. 버퍼 첨부의 녹음에 대해서는, 제 5 장<a href="chapter5.html">「오디오의 혼잡」</a>으로 설명합니다.  </p>
<a name="112344"> </a> 
<h3> 기본 요소:포맷, 믹서, 라인</h3>
<p><a name="112346"> </a>  Java Sound API 를 사용해 사운드를 재생하거나 수중에 넣거나 하려면 , 적어도, 서식 첨부 오디오 데이터, 믹서, 및 라인의 3 개의 요소가 필요합니다. 서식 첨부 오디오 데이터, 믹서, 및 라인입니다. 다음에, 각각 대해 설명합니다.  
</p><a name="112348"> </a> 
<h4> 서식 첨부 오디오 데이터란</h4>
<p><a name="112350"> </a> 서식 첨부 오디오 데이터란, 몇개의 표준 형식 가운데 어느 쪽인가에 포맷 되고 있는 사운드를 가리킵니다. Java Sound API 에서는, 「데이터 형식」과「파일 형식」을 구별하고 있습니다. <em></em><em></em> 
</p><a name="112352"> </a> 
<h4> 데이터 형식</h4>
<p><a name="112354"> </a> 데이터 형식은, 「raw」샘플링 오디오 데이터 (벌써 사운드 파일로부터 읽어내지고 있는 샘플이나 마이크로폰 입력으로부터 받아들여지고 있는 샘플등)의 일련의 바이트를 해석하는 방법을 나타냅니다. 예를 들어, 1 개의 샘플이 무엇 비트로 구성되어 있을까 (사운드의 최단 순간의 표시)나, 사운드의 샘플링 레이트 (샘플링의 간격)를 알 필요가 있습니다. 재생 또는 혼잡의 설정을 실시할 때는, 재생 또는 혼잡을 실시하는 사운드의 데이터 형식을 지정합니다.
</p><p><a name="112356"> </a> Java Sound API 에서는 데이터 형식은 <code>AudioFormat</code> 객체로 나타내집니다. 이 객체에는 다음의 속성이 있습니다.
</p><ul><a name="112358"> </a> 
<li>인코딩 수법 (일반적으로은 펄스부호변조 <PCM>) <a name="112359"> </a> 
<li>채널수 (단청의는 1, 스테레오는 2 등) <a name="112360"> </a> 
<li>샘플링 레이트 ( 각 채널의 1 초간의 샘플수) <a name="112361"> </a> 
<li>샘플의 비트수 (채널마다) <a name="112362"> </a> 
<li>frame rate<a name="112363"> </a> 
<li>frame size (바이트 단위) <a name="112364"> </a> 
<li>바이트순서 (빅 endian 또는 little endian)
<p><a name="114719"> </a> 
</ul>
PCM 는 소리의 파형의 인코딩 수법의 1 개입니다. Java Sound API 에는, 진폭의 선형 양자화를 사용하는 것과 부호 첨부/부호 없음의 정수치를 사용하는 것의 2 종류의 PCM 인코딩이 있습니다. 선형 양자화란, 샘플내에 보존되고 있는 수치가 그 순간의 원의 음압에 정비례 해 (폐해는 제외), 똑같이 그 순간의 소리로 진동하는 스피커나 고막의 변위 에 비례하는 것을 의미합니다. 예를 들어, 콤팩트 디스크는 선형 PCM 인코딩 사운드를 사용합니다. mu-law 인코딩과 a-law 인코딩은 일반적인 비선형 인코딩으로, 오디오 데이터를 보다 작게 압축할 수가 있습니다. 이러한 인코딩 수법은, 일반적으로, 전화나 발화의 녹음에 사용됩니다. 비선형 인코딩에서는 비선형 함수를 사용해, 원의 음성의 진폭을 내부치에 맵 합니다. 이 함수는, 볼륨의 큰 소리보다 작은 소리에, 보다 높은 진폭 분해가능을 갖게하도록(듯이) 설계할 수가 있습니다.  
<p></p><p><a name="112368"> </a> 1 개의 프레임에는, 특정의 시간의 모든 채널의 데이터가 포함됩니다. PCM 인코딩 데이터의 경우는, 프레임은 단지 주어진(given) 순간에 있어서의 모든 채널의 동시 샘플세트이며, 그 이외의 정보는 부수 하지 않습니다. 이 경우, frame rate는 샘플링 레이트에 동일하고, 바이트 단위의 frame size는, 채널수×비트 단위의 샘플 사이즈÷바이트내의 비트수로 요구됩니다.  
</p><p><a name="112370"> </a> 그 외의 인코딩 수법에서는, 프레임에 샘플 이외의 정보가 부수 하는 일이 있습니다. 또 frame rate가 샘플링 레이트와 완전히 다른 일이 있습니다. 예를 들어, MP3 (MPEG-1 Audio Layer 3) 인코딩을 생각합니다. 이 수법은 Java Sound API 의 현버젼에서는 명시적으로는 언급하고는 있지 않습니다만, Java Sound API 의 구현 또는 서드 파티 서비스 프로바이더에 의해 지원되는 경우가 있습니다. MP3 에서는, 각 프레임에는 채널마다의 샘플 뿐만이 아니라, 일련의 샘플이 결정된 압축 데이터가 포함됩니다. 각 프레임에 샘플군전체가 축약 되기 (위해)때문에, frame rate는 샘플링 레이트보다 늦어집니다. 프레임에는 헤더도 포함됩니다. 헤더가 있어도, 바이트 단위의 frame size는, 상당하는 수의 PCM 프레임을 합계한 바이트 사이즈보다 작아집니다. 즉, MP3 는, PCM 보다 컴팩트한 데이터로 하는 것을 목적으로 하고 있습니다. 이러한 인코딩에서는, 샘플링 레이트와 샘플 사이즈란, encode 된 음성의 최종적인 변환 목적이며, DA 컨버터 (DAC)에게 건네지는, PCM 데이터입니다.  
</p><a name="112373"> </a> 
<h4> 파일 형식</h4>
<p><a name="112375"> </a> 파일 형식은, 사운드 파일의 구조에 대해, 파일내의 raw 오디오 데이터의 형식 뿐만이 아니라 파일내에 보존할 수 있는 것 외의 정보도 포함해 지정합니다. 사운드 파일에는, WAVE (WAV 로서도 알려져 PC 에 관련하는 경우가 많다), AIFF (Macintosh 에 관련하는 경우가 많다), AU (UNIX 시스템에 관련하는 경우가 많다)등이 다양한 표준 형식이 있습니다. 사운드 파일의 타입이 다르면(자) 각각의 구조도 다릅니다. 예를 들어, 파일의 헤더내의 데이터의 배열이 다른 일이 있습니다. 헤더에는 설명 정보가 포함되어 일반적으로은 파일의 실제의 오디오 샘플의 전에 있습니다만, 파일 형식에 따라서는 설명과 오디오 데이터를 연속한 「체크」의 형태로 하는 일도 있습니다. 헤더에는, 그 오디오를 사운드 파일에 보존하기 위해서 사용한 데이터 형식의 지정이 포함됩니다. 어느 타입의 사운드 파일에서도 다양한 데이터 형식을 사용할 수 있습니다 (일반적으로은 1 개의 파일에 1 개의 데이터 형식). 또, 다른 파일 형식의 파일에 같은 데이터 형식을 사용할 수도 있습니다.    
</p><p><a name="112377"> </a> Java Sound API 에서는 파일 형식은 <code>AudioFileFormat</code> 객체로 나타내집니다. 이 객체에는 다음의 속성이 있습니다.
</p><ul><a name="112379"> </a> 
<li>파일 타입 (WAVE, AIFF 등) <a name="112380"> </a> 
<li>파일장 (바이트 단위) <a name="112381"> </a> 
<li>파일에 포함되는 오디오 데이터의 길이 (프레임내에서의) <a name="112382"> </a> 
<li>파일에 포함되는 오디오 데이터의 데이터 형식을 지정하는 AudioFormat 객체
<p><a name="112383"> </a> 
</ul>
<code>AudioSystem</code> 클래스 ( 제 3 장<a href="chapter3.html">「오디오 system resource에의 액세스」</a>를 참조)에는, 다른 파일 형식에서 사운드의 read와 기입을 행하기 위한 메소드와 다른 데이터 형식간에 있어서의 형식의 변환을 위한 메소드가 있습니다. 이러한 메소드안에는,<code>AudioInputStream</code> 로 불리는 일종의 스트림을 개입시켜 파일의 내용에 액세스 할 수 있는 것이 있습니다. <code>AudioInputStream</code> 는 총칭 Java <code>InputStream</code> 클래스의 서브 클래스에서, 차례차례 읽어내지는 바이트군을 축 약속하고 있습니다. <code>AudioInputStream</code> 는 슈퍼 클래스의 <code>InputStream</code> 에, 그 바이트의 오디오 데이터 형식의 지식 (<code>AudioFormat</code> 객체로 나타내진다)을 추가한 것입니다. 사운드 파일을 <code>AudioInputStream</code> 로서 읽어들이는 것으로, 사운드 파일의 구조 (헤더, 체크등)를 고려할 필요없게 샘플에 직접 액세스 할 수 있습니다. 1 회의 메소드 호출로, 데이터 형식과 파일 타입에 대해 필요한 모든 정보를 취득할 수 있습니다.  
<p></p><a name="112387"> </a> 
<h4> 믹서란</h4>
<p><a name="112389"> </a> 사운드용의 어플리케이션 프로그래밍 인터페이스 (API)의 상당수는, 오디오 디바이스라고 하는 개념을 사용합니다. <em></em>「디바이스」란, 많은 경우, 물리적인 입출력 장치에의 소프트웨어 인터페이스입니다. 예를 들어, 사운드 입력 디바이스는, 마이크로폰 입력, 라인 레벨의 아날로그 입력, 경우에 따라서는 디지털 오디오 입력 등, 사운드 카드의 입력 기능을 나타내는 일이 있습니다.
</p><p><a name="112391"> </a> Java Sound API 에서는, 디바이스는,<code>Mixer</code> 객체에 의해 나타내집니다. 믹서의 목적은, 1 개(살) 또는 복수의 오디오 입력 스트림과 1 개 또는 복수의 오디오 출력 스트림을 처리하는 것입니다. 일반적으로의 경우, 믹서는 실제, 복수의 입력 스트림을 믹싱 해 1 개의 출력 스트림로 합니다. <code>Mixer</code> 객체는, 사운드 카드와 같은 물리 장치의 사운드 믹싱 기능을 나타낼 수가 있습니다. 그러한 장치에서는, 다양한 입력 길이치로부터 컴퓨터에 보내지는 사운드나 응용 프로그램으로부터 출력 길이치에 보내지는 사운드를 믹싱 할 필요가 있습니다.  
</p><p><a name="113681"> </a> 또 한편,<code>Mixer</code> 객체는, 물리 장치에의 고유의 인터페이스를 가지지 않고 완전하게 소프트웨어내에 구현한 사운드 믹싱 기능을 나타낼 수도 있습니다.
</p>
<p><a name="112393"> </a> Java Sound API 에서는, 사운드 카드상의 마이크로폰 입력등의 원가요소는, 그 자체에서는 디바이스 (믹서)라고는 보여지지 못하고, 믹서에의 입출력의 포트라고 보여집니다. 포트는 일반적으로, 믹서에 들어간다, 또는 믹서로부터 나가는 1 개의 오디오 스트림을 만듭니다. 다만, 스트림은 스테레오와 같이 복수 채널에서도 상관하지 않습니다. 믹서에는, 이러한 포트가 다수 있는 일이 있습니다. 예를 들어, 사운드 카드의 출력 기능을 나타내는 믹서는 복수의 오디오 스트림을 믹싱 해, 믹서에 접속하고 있는 다양한 출력 포트의 1 개 또는 모두에게 믹싱 한 신호를 보냅니다. 이러한 출력 포트로서 헤드폰 잭, 내장 스피커, 라인 레벨 출력등이 있습니다.  </p>
<p><a name="112395"> </a> 라이브 콘서트나 레코딩 스튜디오에서 사용되고 있는 실제의 믹싱 콘솔을 떠올리면(자), Java Sound API 의 믹서의 개념이 이해하기 쉬워집니다(아래의 그림을 참조).  
</p>
<p><a name="112397"> </a>  <img src="images/chapter2.anc1.gif" width="485" height="390"> 
</p>
<blockquote><i>물리 믹싱 콘솔</i></blockquote>
<p><a name="113922"> </a> 물리 장치로서의 믹서에는 복수의 「스트립」(슬라이스라고도 불린다)이 있어, 각각의 스트립은 1 개의 오디오 신호가 처리를 위해서(때문에) 믹서에 보내지는 경로를 나타냅니다. 스트립에는, 그 스트립내의 신호의 볼륨과 빵 (스테레오 이미지에서의 배치)을 조절하기 위한 안주와 컨트롤이 있습니다. 또, 믹서에는 리바브 (잔향)등의 사운드 효과를 위한 독립한 버스가 있어, 내부 또는 외부의 리바브유닛트에 이 버스를 접속할 수 있습니다. 각 스트립에는, 그 스트립의 신호 가운데, 리바브를 걸치는 신호의 양을 조절하는 potentiometer가 있습니다. 리바브를 걸친 ( 「웨트」) 믹스는, 다음에 스트립으로부터의 「드라이」의 신호와 믹싱 됩니다. 물리 믹서는, 믹싱 된 이 최종 신호를 출력 버스에 보내, 출력 버스는 일반적으로은 테이프 레코더 (또는 디스크에 의한 녹음 시스템)와 스피커에 접속하고 있습니다.
</p><p><a name="112401"> </a> 라이브 콘서트의 스테레오 녹음을 생각해 내 보세요. 스테이지상의 다수의 마이크나 전자 악기로부터 나와 있는 케이블 (또는 무선 접속)은 믹싱 콘솔의 입력 플러그에 삽입되고 있습니다. 각각의 입력은, 그림에 나타내도록(듯이) 믹서의 다른 스트립으로 연결되어 있습니다. 음향 기사가, 게인, 빵, 리바브 조절의 설정을 결정합니다. 모든 스트립과 리바브유닛트의 출력이 2 개의 채널에 믹싱 됩니다. 이 2 개의 채널은, 믹서의 2 개의 출력에 보내집니다. 이 출력에는, 스테레오 테이프 레코더의 입력에 접속하고 있는 케이블이 삽입되고 있습니다. 이 2 개의 채널은, 앰프를 개입시켜 음악의 종류와 홀의 크기에 맞추어 선택된 스피커에 보내집니다.
</p><p><a name="112403"> </a> 다음에, 녹음 스튜디오에서, 악기나 가수의 음성을 멀티트랙 테이프 레코더의 다른 트럭에 녹음하는 경우를 생각합니다. 모든 악기와 가수의 음성을 다 녹음하고 나서 , 녹음 기사가 「믹스 다운」을 실시해, 테이프 녹음된 모든 트럭을 정리해, 콤팩트 디스크에 배포 가능한 2 채널 (스테레오) 녹음으로 합니다. 이 경우, 믹서의 각 스트립에의 입력은 마이크로폰은 아니고, 멀티트랙 녹음의 1 개의 트럭입니다. 여기에서도, 녹음 기사는 스트립의 컨트롤을 사용해, 각 트럭의 볼륨, 빵, 및 리바브의 양을 결정할 수가 있습니다. 라이브 콘서트의 예와 같게, 믹서의 출력은 다시 스테레오 레코더와 복수의 스테레오 스피커에 보내집니다.
</p><p><a name="112817"> </a> 상기의 2 개의 예는, 믹서의 2 개의 사용 방법을 나타내고 있습니다. 복수의 입력 채널을 수중에 넣어 소수의 트럭에 정리해 기록해, 믹싱 끝난 신호를 보존하는 방법과 복수의 트럭을 재생하면서 소수의 트럭에 믹스 다운하는 방법입니다.  
</p><p><a name="112407"> </a> Java Sound API 에서는, 믹서는 입력 (오디오의 혼잡)과 출력 (오디오의 재생)에와 같이  사용할 수 있습니다. 입력의 경우는, 믹싱을 위한 오디오를 취득하는 「소스」는, 1 개(살) 이상의 입력 포트입니다. <em></em>믹서는, 수중에 넣어 믹싱 한 오디오 스트림을 「타겟」에 보냅니다. <em></em>타겟은, 응용 프로그램이 믹싱이 끝난 오디오 데이타를 뽑기 시작할 수 있는 객체입니다. 오디오 출력의 경우는, 상황이 거꾸로 됩니다. 믹서의 오디오 소스는, 1 개(살) 이상의 응용 프로그램이 사운드 데이터를 기입할 수 있는 복수의 버퍼를 가지는 1 개(살) 이상의 객체이며, 믹서의 타겟은 1 개 이상의 출력 포트입니다.
</p><a name="113943"> </a> 
<h4> 라인이란</h4>
<p><a name="113931"> </a> 물리 믹싱 콘솔의 예는 Java Sound API 의 「라인」의 개념의 이해에도 도움이 됩니다. <em></em> 
</p>
<p><a name="113932"> </a> 라인이란, 디지털 오디오 「파이프라인」, 즉 오디오를 시스템의 내외에 이송하기 위한 경로의 1 개의 요소입니다. 일반적으로, 라인은 믹서에의 입력 또는 출력의 경로입니다 (기술적으로는, 믹서 자체도 일종의 라인입니다).  </p>
<p><a name="112416"> </a> 오디오 입출력 포트는 라인입니다. 이것들은, 물리 믹싱 콘솔에 접속되고 있는 마이크로폰과 스피커를 닮아 있습니다. 라인의 종류에는 이 외 , 응용 프로그램이 믹서로부터 입력 오디오를 취득하거나 믹서에 출력 오디오를 보내기 위해서(때문에) 사용하는 데이터 패스가 있습니다. 이러한 데이터 패스는, 물리 믹싱 콘솔에 접속되고 있는 멀티트랙 레코더의 트럭을 닮아 있습니다.
</p><p><a name="112418"> </a> Java Sound API 의 라인과 물리적인 믹서의 라인의 차이의 1 개는, Java Sound API 를 흐르는 오디오 데이터는 단청의의 경우와 멀티 채널 (스테레오등)의 경우가 있는 것입니다. 한편, 물리 믹서의 입력과 출력은 각각, 일반적으로은 단일 채널의 사운드입니다. 물리 믹서로부터 복수의 출력 채널을 꺼내려면 , 일반적으로은 복수의 물리 출력이 사용됩니다 (적어도 아날로그 사운드의 경우는, 디지털 출력 잭은 멀티 채널의 경우가 많다). Java Sound API 에서는, 1 개의 라인내의 채널의 수는, 그 라인을 흐르고 있는 데이터의 <code>AudioFormat</code> 에 의해 지정됩니다.
</p><a name="112421"> </a> 
<h4> 오디오 출력 구성의 라인</h4>
<p><a name="112423"> </a> 여기서, 라인과 믹서에 대해, 몇개의 종류를 들고 생각해 보겠습니다. 다음의 그림은, Java Sound API 의 구현의 일부로서 사용할 수 있는, 간단한 오디오 출력 시스템내의 여러종류의 라인을 나타냅니다.  
</p>
<p><a name="112427"> </a>  <img src="images/chapter2.anc.gif" width="380" height="100"> 
</p>
<blockquote><i>오디오 출력용 라인의 구성예</i></blockquote>
<p><a name="112429"> </a> 이 예에서는, 응용 프로그램은 오디오 입력 믹서의 사용 가능한 입력에의 액세스 방법을 가지고 있습니다. 그것은, 1 개(살) 또는 복수의 「클립」과「소스 데이터 라인」입니다. <em></em><em></em>클립이란, 오디오 데이터를 미리 로드하고 나서 재생할 수 있는 믹서 입력 (라인의 일종)입니다. 소스 데이터 라인은, 오디오 데이터의 리얼타임의 스트림을 받는 믹서 입력입니다. 응용 프로그램은 사운드 파일로부터 클립에 오디오 데이터를 미리 로드합니다. 다음에, 응용 프로그램은 그 외의 오디오 데이터를, 1 회에 1 버퍼분씩 소스 데이터 라인에 보냅니다. 각 라인에는 리바브, 게인, 빵의 컨트롤이 있습니다. 믹서는 모든 라인으로부터 데이터를 읽어들여, 드라이의 오디오 신호와 리바브를 걸친 웨트의 오디오 신호를 믹싱 합니다. 믹서는, 스피커, 헤드폰 잭, 라인 아웃 잭등의 1 살 이상의 출력 포트에 최종적인 출력을 전달합니다.
</p><p><a name="112431"> </a> 이 그림에서는, 다양한 라인은 독립한 구형으로 나타내지고 있습니다만, 이것들은 모두 믹서가 소유해서 , 믹서의 일부라고 생각할 수가 있습니다. 리바브, 게인, 및 빵의 구형은, 라인을 흐르고 있는 데이터에 대해서 믹서가 실행하는 처리 컨트롤을 나타내서 , 라인이 아닙니다.  
</p><p><a name="112433"> </a> 이것은, 이 API 로 지원할 수 있는 믹서의 일례입니다. 모든 오디오 구성에, 그림으로 가리켜져 모든 기능이 있는 것은 아닙니다. 개개의 소스 데이터 라인으로 빵을 지원하지 않는 경우나, 믹서가 리바브를 구현하지 않는 경우 등도 있습니다.
</p><a name="112435"> </a> 
<h4> 오디오 입력 구성의 라인</h4>
<p><a name="112437"> </a> 단순한 오디오 입력 시스템도 같습니다.  
</p>
<p><a name="112439"> </a>  <img src="images/chapter2.anc2.gif" width="291" height="90"> 
</p>
<blockquote><i>오디오 입력용 라인의 구성예</i></blockquote>
<p><a name="112860"> </a> 여기에서는, 데이터는 1 개 이상의 입력 포트 (일반적으로은 마이크로폰 또는 라인 입력 잭)로부터 믹서에 흐릅니다. 게인과 빵이 적용되어 믹서는 믹서의 타겟 데이터 라인을 경유해, 수중에 넣은 데이터를 어플리케이션에 전달합니다. 타겟 데이터 라인은, 스트리밍 된 입력 사운드의 혼합이 포함되는 믹서 출력입니다. 무엇보다 단순한 믹서의 타겟 데이터 라인은 1 개 뿐입니다만, 수중에 넣은 데이터를 동시에 복수의 타겟 데이터 라인에 전달할 수 있는 믹서도 있습니다.
</p><a name="112445"> </a> 
<h4> Line 인터페이스의 계층</h4>
<p><a name="112447"> </a> 여기까지는 라인과 믹서에 대해, 기능면으로부터 몇개인가 봐 왔습니다만, 여기로부터는, 프로그램의 시점으로부터의 고찰을 실시합니다. 몇개의 라인은, 기본 인터페이스 <code>Line</code> 의 서브 인터페이스에 의해 정의되고 있습니다. 인터페이스의 계층을 다음에 나타냅니다.  
</p>
<p><a name="112449"> </a>  <img src="images/chapter2.anc3.gif" width="402" height="209"> 
</p>
<blockquote><i>Line 인터페이스의 계층</i></blockquote>
<p><a name="112452"> </a> 기본 인터페이스 <code>Line</code> 에는, 모든 라인에 공통되는 최소한의 기능이 기술되고 있습니다.  
</p><ul><a name="112454"> </a> 
<li>컨트롤<a name="112456"> </a> 
<blockquote>데이터 라인 및 포트는, 많은 경우, 라인을 통과하는 오디오 신호에 작용하는 컨트롤세트를 가지고 있습니다. Java Sound API 에서는 컨트롤 클래스를 지정합니다. 컨트롤 클래스를 사용하면(자), 게인 (신호의 데시벨 단위의 볼륨에 영향), 빵 (사운드의 좌우의 위치에 영향), 리바브 (사운드에 잔향을 추가해 다양한 종류의 실내 음향을 에뮤레이트), 및 샘플링 레이트 (재생 레이트와 소리의 피치에 영향)등이 다양한 면으로부터 사운드를 조작할 수 있습니다. </blockquote>
<a name="112458"> </a> 
<li>오픈 상태와 클로즈 상태<a name="112460"> </a> 
<blockquote>라인의 오픈이 정상 종료하면(자), 반드시 라인에 자원을 할당할 수 있습니다. 믹서가 가지는 라인수는 한정되어 있기 (위해)때문에, 복수의 응용 프로그램 (또는 같은 어플리케이션)이 믹서의 라인의 사용으로 경합 할 가능성이 있습니다. 라인의 클로즈는, 라인으로 사용된 모든 자원을 즉시 해제할 수 있는 것을 나타냅니다.  </blockquote>
<a name="112462"> </a> 
<li>이벤트<a name="112464"> </a> 
<blockquote>라인은 오픈시 또는 클로즈시에 이벤트를 생성합니다. <code>Line</code> 의 서브 인터페이스는 그 외의 종류의 이벤트를 발행할 수 있습니다. 라인이 이벤트를 생성하면(자), 그 라인상에서 이벤트가 발생할 때까지 「대기」하도록(듯이) 등록된 모든 객체에 그 이벤트가 송신됩니다. 응용 프로그램은 이러한 객체를 작성해, 라인 이벤트가 발생할 때까지 대기하도록(듯이) 등록해, 필요에 따라서 그 이벤트에 응답할 수가 있습니다. </blockquote>
<p><a name="112466"> </a> 
</ul>
다음에,<code>Line</code> 인터페이스의 서브 인터페이스에 대해 생각합니다.
<p></p><p><a name="112468"> </a>  <code>Ports</code> 는, 오디오 디바이스에 대한 오디오의 입력 또는 출력을 위한 단순한 라인입니다. 벌써 설명했던 대로, 일반적인 포트의 종류에는, 마이크로폰, 라인 입력, CD-ROM 드라이브, 스피커, 헤드폰, 라인 출력등이 있습니다.  
</p><p><a name="112470"> </a> <code>Mixer</code> 인터페이스는 당연히 믹서를 나타내, 벌써 설명한 것처럼 하드웨어 디바이스 또는 소프트웨어 디바이스입니다. <code>Mixer</code> 인터페이스는, 믹서의 라인을 취득하기 위한 메소드를 제공합니다. 믹서의 라인에는, 오디오를 믹서에 보내는 소스 라인과 믹서가 믹싱 끝난 오디오를 배웅하는 타겟 라인이 있습니다. 오디오 입력 믹서의 경우, 소스 라인은 마이크로폰 입력등의 입력 포트로, 타겟 라인은 오디오를 응용 프로그램에 보내는 <code>TargetDataLines</code> (이후에로 설명)입니다. 한편, 오디오 출력 믹서의 경우, 소스 라인은 응용 프로그램이 오디오 데이터를 보내는 <code>Clips</code> 나 <code>SourceDataLines</code> (이후에로 설명)로, 타겟 라인은 스피커등의 출력 포트입니다.
</p><p><a name="112472"> </a> <code>Mixer</code> 는, 1 개(살) 이상의 소스 라인과 1 개 이상의 타겟 라인을 가지는 것이라고 정의됩니다. 이 정의에 의하면, 믹서는 실제로 데이터를 믹싱 하지 않아도 상관없기 때문에, 믹서의 소스 라인이 1 개만이라고 하는 가능성도 있습니다. <code>Mixer</code> API 는 다양한 디바이스를 포함하기 위한의 것입니다만, 일반적으로은, 이 API 로 믹싱이 지원되고 있습니다.
</p><p><a name="112474"> </a> <code>Mixer</code> 인터페이스에서는 동기가 지원되므로, 복수의 믹서의 라인을 동기 그룹으로서 취급하도록(듯이) 지정할 수 있습니다. 지정 후는, 각 라인을 개별적으로 제어할 필요는 없고, 그룹의 라인의 어떤 것인가에 단일의 메세지를 보내는 것으로, 그룹의 모든 데이터 라인을 개시, 정지, 또는 클로즈 할 수가 있습니다. 이 기능을 가지는 믹서를 사용하면(자), 라인간에 샘플 정밀도의 동기를 얻을 수 있습니다.
</p><p><a name="112476"> </a> 총칭 <code>Line</code> 인터페이스에는, 재생과 녹음의 개시와 정지를 실시하는 수단은 없습니다. 그 때문에(위해)는, 데이터 라인이 필요합니다. <code>DataLine</code> 인터페이스는,<code>Line</code> 의 기능 이외에 다음의 보완적인 미디어 관련 기능을 제공합니다.
</p><blockquote><a name="112477"> </a> 
<li>오디오 형식 <a name="112479"> </a> 
<blockquote>각 데이터 라인의 데이터 스트림에는, 오디오 형식을 관련지을 수 있고 있습니다.  </blockquote>
<a name="112987"> </a> 
<li>미디어 위치<a name="112482"> </a> 
<blockquote>데이터 라인은, 미디어내의 현재의 위치를 샘플 프레임수로 나타내 통지할 수 있습니다. 이것은, 오픈 후에 데이터 라인보다 받아들여졌는지, 또는 렌더링 된 샘플 프레임의 수를 나타냅니다.  </blockquote>
<a name="112483"> </a> 
<li>버퍼 사이즈<a name="112485"> </a> 
<blockquote>데이터 라인의 내부 버퍼의 사이즈 (바이트수)입니다. 소스 데이터 라인의 경우는, 내부 버퍼에의 데이터의 기입이 가능합니다. 타겟 데이터 라인의 경우는, 내부 버퍼로부터의 데이터의 read가 가능합니다.  </blockquote>
<a name="112486"> </a> 
<li>레벨 (오디오 신호의 현재의 진폭)
<p>
<a name="112487"> </a> 
<li>재생 또는 혼잡의 개시 및 정지
<p>
<a name="112488"> </a> 
<li>재생과 혼잡의 일시정지와 재개
<p>
<a name="112489"> </a> 
<li>플래시 (큐로부터 미처리 데이터를 파기한다)
<p>
<a name="112490"> </a> 
<li>드레인 (모든 미처리 데이터가 쓸어 내져 데이터 라인의 버퍼가 비울 때까지 블록 한다)
<p>
<a name="112491"> </a> 
<li>액티브 상태<a name="112493"> </a> 
<blockquote>액티브한 재생동작 또는 믹서의 입출력 오디오 데이터의 혼잡 동작에 종사하고 있는 데이터 라인은 「액티브 상태」라고 보입니다.  </blockquote>
<a name="113005"> </a> 
<li>이벤트<a name="112496"> </a> 
<blockquote>액티브한 재생동작 또는 믹서의 입출력 오디오 데이터의 혼잡 동작의 개시시와 종료시에,<code>START</code> 및 <code>STOP</code> 이벤트가 생성됩니다.  </blockquote>
</blockquote>
<p><a name="112499"> </a> <code>TargetDataLine</code> 는, 믹서로부터 오디오 데이터를 받습니다. 일반적으로, 믹서는 마이크로폰등의 포트로부터 오디오 데이타를 뽑아 붐비고 있기 (위해)때문에, 타겟 라인의 버퍼에 데이터를 두기 전에, 수중에 넣은 오디오를 처리 또는 믹싱 할 수 있습니다. <code>TargetDataLine</code> 인터페이스는, 타겟 데이터 라인의 버퍼로부터 데이터를 읽어들이기 위한 메소드, 및 현재 read가 가능한 데이터량을 특정하기 위한 메소드를 제공합니다.
</p><p><a name="112501"> </a> <code>SourceDataLine</code> 는, 재생용의 오디오 데이터를 받습니다. <code>SourceDataLine</code> 는, 재생용으로 소스 데이터 라인의 버퍼에 데이터를 기입하기 위한 메소드, 및 라인이 블록 되지 않고 받을 준비가 되어 있는 데이터량을 특정하기 위한 메소드를 제공합니다.  
</p><p><a name="112503"> </a> <code>Clip</code> 는, 재생전에 오디오 데이터를 로드할 수 있는 데이터 라인입니다. 데이터는 스트리밍은 아니고 사전에 로드 되기 (위해)때문에, 클립의 듀레이션이 재생전에 알아, 미디어내에서의 개시 위치를 임의에 선택할 수 있습니다. 클립은 루프 할 수 있습니다. 즉, 재생시에 2 개의 지정한 루프점간의 모든 데이터를, 지정한 회수 또는 무기한으로 반복할 수가 있습니다.
</p><p><a name="112505"> </a> 이 장에서는, 샘플링 오디오 API 의 중요한 인터페이스와 클래스의 대부분에 임해서 설명했습니다. 차장으로부터는, 이러한 객체를 응용 프로그램으로부터 액세스 해 사용하는 방법에 대해 설명합니다.
</p>
<p>&nbsp;</p></body>
</html>
